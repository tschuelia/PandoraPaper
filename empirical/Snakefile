# Snakefile to benchmark a Pandora run on an empirical dataset

"""
This Snakefile is used to benchmark a Pandora run on an empirical dataset. For benchmarking on our institutional
servers, we need to read and generate all files locally otherwise the benchmark is corrupted by the overhead of
the external file system. This is why we copy the files to a local directory before running the benchmark, and copy
the results back to the external file system afterward.
"""
import pathlib

import pandas as pd
import yaml


# CONFIG
# ---------------
dataset_identifier = "HO-Cayonu"
eigen_prefix = "Cayonu/westEurasian_ancient/Cayonu_ModernWestEurasia"
embedding_populations = "Cayonu/modern.population.txt"
file_format = "ANCESTRYMAP"

algo = "PCA"
n_components = 10

n_bootstraps = 100
n_threads = 20
seed = 42
bootstrap_convergence_check = False
# ---------------

external = pathlib.Path("/hits/fast/cme/schmidja/Pandora/PandoraPaper/empirical")
dataset_prefix = external / "datasets" / eigen_prefix

geno_file_external = pathlib.Path(f"{dataset_prefix}.geno")
ind_file_external = pathlib.Path(f"{dataset_prefix}.ind")
snp_file_external = pathlib.Path(f"{dataset_prefix}.snp")

conv_suffix = "convergence" if bootstrap_convergence_check else "no_convergence"
result_prefix_external = external / "results" / algo / conv_suffix

local = pathlib.Path()
local_results = local / "results"


rule all:
    input:
        result_prefix_external / dataset_identifier / f"{dataset_identifier}.pandora.parquet"


rule copy_dataset_to_local:
    input:
        geno_file = geno_file_external,
        ind_file = ind_file_external,
        snp_file = snp_file_external
    output:
        geno_file = local / f"{dataset_identifier}.geno",
        ind_file = local / f"{dataset_identifier}.ind",
        snp_file = local / f"{dataset_identifier}.snp"
    run:
        shell("cp {input.geno_file} {output.geno_file}")
        shell("cp {input.ind_file} {output.ind_file}")
        shell("cp {input.snp_file} {output.snp_file}")

        if embedding_populations is not None:
            emb_file = local / f"{dataset_identifier}.populations.txt"
            shell("cp {embedding_populations} {emb_file}")

rule run_pandora:
    input:
        geno_file = rules.copy_dataset_to_local.output.geno_file
    output:
        pandora_results = local_results / "pandora.txt",
        log = local_results / "pandora.log"
    log:
        out = local / "pandora.out",
        err = local / "pandora.err"
    run:
        # Create Pandora config file
        config_file = local / f"{dataset_identifier}_config.yaml"

        config = {
            "dataset_prefix": str(pathlib.Path(input.geno_file).stem),
            "file_format": file_format,
            "result_dir": str(local_results),
            "n_replicates": n_bootstraps,
            "threads": n_threads,
            "seed": seed,
            "embedding_algorithm": algo,
            "bootstrap_convergence_check": bootstrap_convergence_check
        }

        if embedding_populations is not None:
            config["embedding_populations"] = local / f"{dataset_identifier}.populations.txt"

        yaml.dump(config, config_file.open("w"))

        shell("pandora -c {config_file} > {log.out} 2> {log.err}")


rule move_results_to_external:
    input:
        rules.run_pandora.output.pandora_results,
    output:
        pandora_results_ext = result_prefix_external / dataset_identifier / "pandora.txt",
        pandora_log_ext = result_prefix_external / dataset_identifier / "pandora.log"
    run:
        outdir = result_prefix_external / dataset_identifier
        outdir.mkdir(exist_ok=True, parents=True)
        shell(f"mv {local_results}/* {outdir}/")


rule collect_results:
    input:
        pandora_results = rules.move_results_to_external.output.pandora_results_ext,
        pandora_log = rules.move_results_to_external.output.pandora_log_ext
    output:
        summary = result_prefix_external / dataset_identifier / f"{dataset_identifier}.pandora.parquet"
    run:
        results = {
            "dataset": dataset_identifier,
            "n_components": n_components,
            "n_bootstraps": n_bootstraps,
            "n_threads": n_threads,
            "seed": seed,
            "bootstrap_convergence_check": bootstrap_convergence_check,
            "embedding_algorithm": algo
        }

        for line in open(input.pandora_log).readlines():
            line = line.strip()
            if line.startswith("Pandora Stability"):
                results["PS"] = float(line.split(":")[1].strip())
            elif line.startswith("> average"):
                psv_summary = line.split(":")[1].strip()
                psv_mean, psv_stdev = psv_summary.split("Â±")
                results["PSV_mean"] = float(psv_mean.strip())
                results["PSV_stdev"] = float(psv_stdev.strip())
            elif line.startswith("> median"):
                results["PSV_median"] = float(line.split(":")[1].strip())
            elif line.startswith("> lowest"):
                results["PSV_min"] = float(line.split(":")[1].strip())
            elif line.startswith("> highest"):
                results["PSV_max"] = float(line.split(":")[1].strip())
            elif line.startswith("Total runtime"):
                # Total runtime: 0:53:06 (3186 seconds)
                _, runtime = line.rsplit("(")
                runtime = runtime.strip("seconds)")
                results["runtime"] = int(runtime)

        results = pd.DataFrame(results, index=[0])
        results.to_parquet(output.summary)


