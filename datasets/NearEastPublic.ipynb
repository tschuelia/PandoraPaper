{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recreating the NearEastPublic dataset analyses\n",
    "We used the publicly available data from Lazaridis, I., Patterson, N., Mittnik, A. et al. Ancient human genomes suggest three ancestral populations for present-day Europeans. Nature 513, 409â€“413 (2014). https://doi.org/10.1038/nature13673"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note on smartpca settings:\n",
    "In their original publication, Lazarids et al. set `numoutlieriters: 0` for the smartpca PCA analyses. Back then the `shrinkmode` option was not available in smartpca, so we set `shrinkmode: NO`. \n",
    "The HO-array is often used as reference for mapping ancient samples (especially the HO-west subset). In many analyses the default smartpca settigs are used, which corresponds to `numoutlieriters: 5`. So we additionally analysed this setting. Since its introduction, the `shrinkmode` is frequently applied, so we also did all analyses with `shrinkmode: YES` as well.\n",
    "\n",
    "This leads to four tested settings for the HO-west dataset:\n",
    "- `numoutlieriters: 0` and `shrinkmode: NO`\n",
    "- `numoutlieriters: 0` and `shrinkmode: YES`\n",
    "- `numoutlieriters: 5` and `shrinkmode: NO`\n",
    "- `numoutlieriters: 5` and `shrinkmode: YES`\n",
    "\n",
    "To economize on resources, we did not test all four settings for the HO-global set. Instead, we only analyzed the `numoutlieriters: 0` and `shrinkmode: NO` combination. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from filter_merge_utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:31:38.148735Z",
     "start_time": "2023-11-02T19:31:37.535350Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment and run the following cell to download the dataset from the Reich Lab website."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "! wget https://reich.hms.harvard.edu/sites/reich.hms.harvard.edu/files/inline-files/NearEastPublic.tar.gz\n",
    "! mkdir NearEastPublic && mv NearEastPublic.tar.gz NearEastPublic\n",
    "! cd NearEastPublic && tar -xf NearEastPublic.tar.gz\n",
    "! mkdir raw && mv ./* raw\n",
    "! mkdir global && mkdir westEurasia && mkdir westEurasia_ancient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T12:36:18.781309Z",
     "start_time": "2023-10-23T12:36:18.779049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base_dir = pathlib.Path(\"NearEastPublic\")\n",
    "dataset_prefix = base_dir / \"raw\" / \"HumanOriginsPublic2068\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:31:40.153643Z",
     "start_time": "2023-11-02T19:31:40.146421Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global EigenDataset\n",
    "Next, we filter the dataset to reproduce the dataset of global samples.\n",
    "For this, we use the list of global populations as provided in the supplement of the publication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "global_prefix = base_dir / \"global\" / \"HumanOriginsPublic2068.global\"\n",
    "global_population_file = pathlib.Path(f\"{global_prefix}.populations.txt\")\n",
    "\n",
    "global_set = get_pop_set_from_string(\"AA, Algonquin, Ami, Atayal, Basque, BedouinB, Biaka, Bougainville, Brahui, Cabecar, Chipewyan, Chukchi, Damara, Datog, Dinka, Esan, Eskimo, Georgian, Gui, GujaratiD, Hadza, Han, Itelmen, Ju_hoan_North, Kalash, Karitiana, Kharia, Korean, Koryak, LaBrana, Lahu, Lodhi, Loschbour, MA1, Mala, Mandenka, Masai, Mbuti, Mozabite, Naxi, Nganasan, Onge, Papuan, Pima, Sandawe, Sardinian, She, Somali, Stuttgart, Surui, Tubalar, Ulchi, Vishwabrahmin, Yoruba\")\n",
    "save_pop_set(global_set, global_population_file)\n",
    "\n",
    "# filter the global populations\n",
    "filter_dataset(\n",
    "    prefix_in=dataset_prefix,\n",
    "    prefix_out=global_prefix,\n",
    "    poplistname=global_population_file,\n",
    "    redo=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:31:44.474397Z",
     "start_time": "2023-11-02T19:31:44.465148Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## West-Eurasian EigenDataset\n",
    "Next, we filter the dataset to reproduce the dataset of west-eurasion samples.\n",
    "For this, we use the list of west-eurasian populations as provided in the supplement of the publication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "westeurasian_prefix = base_dir / \"westEurasia\" / \"HumanOriginsPublic2068.westEurasian\"\n",
    "westeurasian_population_file = pathlib.Path(f\"{westeurasian_prefix}.populations.txt\")\n",
    "\n",
    "westeurasian_set = get_pop_set_from_string(\"Abkhasian, Adygei, Albanian, Armenian, Ashkenazi_Jew, Jew_Ashkenazi, Balkar, Basque, BedouinA, BedouinB, Belarusian, Bergamo, Bulgarian, Canary_Islanders, Canary_Islander, Chechen, Croatian, Cypriot, Czech, Druze, English, Estonian, Finnish, French, French_South, Georgian, Georgian_Jew, Jew_Georgian, Greek, Hungarian, Icelandic, Iranian, Iranian_Jew, Jew_Iranian, Iraqi_Jew, Jew_Iraqi, Italian_South, Jordanian, Kumyk, LaBrana, Lebanese, Lezgin, Libyan_Jew, Jew_Libyan, Lithuanian, Loschbour, Maltese, Mordovian, Moroccan_Jew, Jew_Moroccan, Motala12, Motala_merge, North_Ossetian, Norwegian, Orcadian, Palestinian, Russian, Sardinian, Saudi, Scottish, Sicilian, Spanish, Spanish_North, Stuttgart, Syrian, Tunisian_Jew, Jew_Tunisian, Turkish, Turkish_Jew, Jew_Turkish, Tuscan, Ukrainian, Yemenite_Jew, Jew_Yemenite\")\n",
    "\n",
    "save_pop_set(westeurasian_set, westeurasian_population_file)\n",
    "\n",
    "# filter the westeurasian populations\n",
    "filter_dataset(\n",
    "    prefix_in=dataset_prefix,\n",
    "    prefix_out=westeurasian_prefix,\n",
    "    poplistname=westeurasian_population_file,\n",
    "    redo=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:40:00.228956Z",
     "start_time": "2023-11-02T19:39:21.576818Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging the west-eurasian samples with ancient samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: /var/folders/c3/6cf6l4n106v0gfcqwr1bt8nr0000gn/T/tmpjq5ork21\n",
      "geno1: NearEastPublic/westEurasia/HumanOriginsPublic2068.westEurasian.geno\n",
      "snp1: NearEastPublic/westEurasia/HumanOriginsPublic2068.westEurasian.snp\n",
      "ind1: NearEastPublic/westEurasia/HumanOriginsPublic2068.westEurasian.ind\n",
      "geno2: NearEastPublic/raw/AncientLazaridis2016.geno\n",
      "snp2: NearEastPublic/raw/AncientLazaridis2016.snp\n",
      "ind2: NearEastPublic/raw/AncientLazaridis2016.ind\n",
      "genooutfilename: /var/folders/c3/6cf6l4n106v0gfcqwr1bt8nr0000gn/T/tmpnbouugix/merged.geno\n",
      "snpoutfilename: /var/folders/c3/6cf6l4n106v0gfcqwr1bt8nr0000gn/T/tmpnbouugix/merged.snp\n",
      "indoutfilename: /var/folders/c3/6cf6l4n106v0gfcqwr1bt8nr0000gn/T/tmpnbouugix/merged.ind\n",
      "hashcheck: NO\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "numsnps: 621799  numindivs: 1107\n",
      "packedancestrymap output\n",
      "##end of mergeit run\n"
     ]
    },
    {
     "data": {
      "text/plain": "538"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancient_prefix = base_dir / \"raw\" / \"AncientLazaridis2016\"\n",
    "merged_prefix = base_dir / \"westEurasia_ancient\" / \"AncientLazaridis2016_ModernWestEurasia\"\n",
    "\n",
    "# The ancient samples contain some samples we want to exclude prior to PCA (e.g. Chimp sequences)\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    tmpdir = pathlib.Path(tmpdir)\n",
    "    tmp_merged_prefix = tmpdir / \"merged\"\n",
    "    merge_datasets(\n",
    "        prefix_ds1=westeurasian_prefix,\n",
    "        prefix_ds2=ancient_prefix,\n",
    "        prefix_out=tmp_merged_prefix,\n",
    "        redo=True\n",
    "    )\n",
    "\n",
    "    ind_file = pathlib.Path(f\"{tmp_merged_prefix}.ind\")\n",
    "    ind_df = indfile_to_dataframe(ind_file)\n",
    "\n",
    "    keep_populations = tmpdir / \"exclude.poplist.txt\"\n",
    "    exclude = [\"Mota\", \"Denisovan\", \"Chimp\", \"Mbuti.DG\", \"Altai\",\n",
    "               \"Vi_merge\", \"Clovis\", \"Kennewick\", \"Chuvash\", \"Ust_Ishim\",\n",
    "               \"AG2\", \"MA1\", \"MezE\", \"hg19ref\", \"Kostenki14\"]\n",
    "    keep = [p for p in ind_df.population.unique() if p not in exclude]\n",
    "    keep_populations.open(\"w\").write(\"\\n\".join(keep))\n",
    "\n",
    "    filter_dataset(\n",
    "        prefix_in=tmp_merged_prefix,\n",
    "        prefix_out=merged_prefix,\n",
    "        poplistname=keep_populations,\n",
    "        redo=True\n",
    "    )\n",
    "\n",
    "# finally, save the population names of the modern samples in a specific file such that we can later use it for the PCA projection\n",
    "ancient_populations = [\"Anatolia_ChL\", \"Anatolia_N\", \"Armenia_ChL\", \"Armenia_EBA\", \"Armenia_MLBA\", \"CHG\", \"EHG\", \"Europe_EN\", \"Europe_LNBA\", \"Europe_MNChL\", \"Iberia_BA\", \"Iran_ChL\", \"Iran_HotuIIIb\", \"Iran_LN\", \"Iran_N\", \"Levant_BA\", \"Levant_N\", \"Natufian\", \"SHG\", \"Steppe_EMBA\", \"Steppe_Eneolithic\", \"Steppe_IA\", \"Steppe_MLBA\", \"Switzerland_HG\", \"WHG\"]\n",
    "\n",
    "ind_file = pathlib.Path(f\"{merged_prefix}.ind\")\n",
    "ind_df = indfile_to_dataframe(ind_file)\n",
    "\n",
    "modern = [p for p in ind_df.population.unique() if p not in ancient_populations]\n",
    "modern_populations = base_dir / \"westEurasia_ancient\" / \"modern.poplist.txt\"\n",
    "modern_populations.open(\"w\").write(\"\\n\".join(modern))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:41:28.270576Z",
     "start_time": "2023-11-02T19:40:49.029074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
