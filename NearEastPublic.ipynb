{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recreating the NearEastPublic dataset analyses\n",
    "We used the publicly available data from Lazaridis, I., Patterson, N., Mittnik, A. et al. Ancient human genomes suggest three ancestral populations for present-day Europeans. Nature 513, 409–413 (2014). https://doi.org/10.1038/nature13673"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from filter_merge_utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment and run the following cell to download the dataset from the Reich Lab website."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! wget https://reich.hms.harvard.edu/sites/reich.hms.harvard.edu/files/inline-files/NearEastPublic.tar.gz\n",
    "# ! mkdir NearEastPublic && mv NearEastPublic.tar.gz NearEastPublic\n",
    "# ! cd NearEastPublic && tar -xf NearEastPublic.tar.gz\n",
    "# ! mkdir raw && mv ./* raw\n",
    "# ! mkdir global && mkdir westEurasia && mkdir westEurasia_ancient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_dir = pathlib.Path(\"NearEastPublic\")\n",
    "dataset_prefix = base_dir / \"raw\" / \"HumanOriginsPublic2068\"\n",
    "\n",
    "smartpca_settings = {\n",
    "    \"numoutlieriter\": 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global Dataset\n",
    "Next, we filter the dataset to reproduce the dataset of global samples.\n",
    "For this, we use the list of global populations as provided in the supplement of the publication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global_prefix = base_dir / \"global\" / \"HumanOriginsPublic2068.global\"\n",
    "global_population_file = pathlib.Path(f\"{global_prefix}.populations.txt\")\n",
    "\n",
    "global_set = get_pop_set_from_string(\"AA, Algonquin, Ami, Atayal, Basque, BedouinB, Biaka, Bougainville, Brahui, Cabecar, Chipewyan, Chukchi, Damara, Datog, Dinka, Esan, Eskimo, Georgian, Gui, GujaratiD, Hadza, Han, Itelmen, Ju_hoan_North, Kalash, Karitiana, Kharia, Korean, Koryak, LaBrana, Lahu, Lodhi, Loschbour, MA1, Mala, Mandenka, Masai, Mbuti, Mozabite, Naxi, Nganasan, Onge, Papuan, Pima, Sandawe, Sardinian, She, Somali, Stuttgart, Surui, Tubalar, Ulchi, Vishwabrahmin, Yoruba\")\n",
    "save_pop_set(global_set, global_population_file)\n",
    "\n",
    "# filter the global populations\n",
    "filter_dataset(\n",
    "    prefix_in=dataset_prefix,\n",
    "    prefix_out=global_prefix,\n",
    "    poplistname=global_population_file,\n",
    "    redo=False\n",
    ")\n",
    "\n",
    "# save a config file used for the Pandora analysis\n",
    "configfile = base_dir / \"global\" / \"global.pandora.yaml\"\n",
    "save_pandora_config(\n",
    "    global_prefix,\n",
    "    base_dir / \"global\" / \"results\",\n",
    "    smartpca_settings,\n",
    "    configfile\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## West-Eurasian Dataset\n",
    "Next, we filter the dataset to reproduce the dataset of west-eurasion samples.\n",
    "For this, we use the list of west-eurasian populations as provided in the supplement of the publication."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "westeurasian_prefix = base_dir / \"westEurasia\" / \"HumanOriginsPublic2068.westEurasian\"\n",
    "westeurasian_population_file = pathlib.Path(f\"{westeurasian_prefix}.populations.txt\")\n",
    "\n",
    "westeurasian_set = get_pop_set_from_string(\"Abkhasian, Adygei, Albanian, Armenian, Ashkenazi_Jew, Balkar, Basque, BedouinA, BedouinB, Belarusian, Bergamo, Bulgarian, Canary_Islanders, Chechen, Croatian, Cypriot, Czech, Druze, English, Estonian, Finnish, French, French_South, Georgian, Georgian_Jew, Greek, Hungarian, Icelandic, Iranian, Iranian_Jew, Iraqi_Jew, Italian_South, Jordanian, Kumyk, LaBrana, Lebanese, Lezgin, Libyan_Jew, Lithuanian, Loschbour, Maltese, Mordovian, Moroccan_Jew, Motala12, Motala_merge, North_Ossetian, Norwegian, Orcadian, Palestinian, Russian, Sardinian, Saudi, Scottish, Sicilian, Spanish, Spanish_North, Stuttgart, Syrian, Tunisian_Jew, Turkish, Turkish_Jew, Tuscan, Ukrainian, Yemenite_Jew\")\n",
    "save_pop_set(westeurasian_set, westeurasian_population_file)\n",
    "\n",
    "# filter the westeurasian populations\n",
    "filter_dataset(\n",
    "    prefix_in=dataset_prefix,\n",
    "    prefix_out=westeurasian_prefix,\n",
    "    poplistname=westeurasian_population_file,\n",
    "    redo=False\n",
    ")\n",
    "\n",
    "# save a config file used for the Pandora analysis\n",
    "configfile = base_dir / \"westEurasia\" / \"westEurasia.pandora.yaml\"\n",
    "save_pandora_config(\n",
    "    westeurasian_prefix,\n",
    "    base_dir / \"westEurasia\" / \"results\",\n",
    "    smartpca_settings,\n",
    "    configfile\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging the west-eurasian samples with ancient samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ancient_prefix = base_dir / \"raw\" / \"AncientLazaridis2016\"\n",
    "merged_prefix = base_dir / \"westEurasia_ancient\" / \"AncientLazaridis2016_ModernWestEurasia\"\n",
    "\n",
    "# The ancient samples contain some samples we want to exclude prior to PCA (e.g. Chimp sequences)\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    tmpdir = pathlib.Path(tmpdir)\n",
    "    tmp_merged_prefix = tmpdir / \"merged\"\n",
    "    merge_datasets(\n",
    "        prefix_ds1=westeurasian_prefix,\n",
    "        prefix_ds2=ancient_prefix,\n",
    "        prefix_out=tmp_merged_prefix,\n",
    "        redo=False\n",
    "    )\n",
    "\n",
    "    ind_file = pathlib.Path(f\"{tmp_merged_prefix}.ind\")\n",
    "    ind_df = indfile_to_dataframe(ind_file)\n",
    "\n",
    "    keep_populations = tmpdir / \"exclude.poplist.txt\"\n",
    "    exclude = [\"Mota\", \"Denisovan\", \"Chimp\", \"Mbuti.DG\", \"Altai\",\n",
    "               \"Vi_merge\", \"Clovis\", \"Kennewick\", \"Chuvash\", \"Ust_Ishim\",\n",
    "               \"AG2\", \"MA1\", \"MezE\", \"hg19ref\", \"Kostenki14\"]\n",
    "    keep = [p for p in ind_df.population.unique() if p not in exclude]\n",
    "    keep_populations.open(\"w\").write(\"\\n\".join(keep))\n",
    "\n",
    "    filter_dataset(\n",
    "        prefix_in=tmp_merged_prefix,\n",
    "        prefix_out=merged_prefix,\n",
    "        poplistname=keep_populations,\n",
    "        redo=False\n",
    "    )\n",
    "\n",
    "# finally, save the population names of the modern samples in a specific file such that we can later use it for the PCA projection\n",
    "ancient_populations = [\"Anatolia_ChL\", \"Anatolia_N\", \"Armenia_ChL\", \"Armenia_EBA\", \"Armenia_MLBA\", \"CHG\", \"EHG\", \"Europe_EN\", \"Europe_LNBA\", \"Europe_MNChL\", \"Iberia_BA\", \"Iran_ChL\", \"Iran_HotuIIIb\", \"Iran_LN\", \"Iran_N\", \"Levant_BA\", \"Levant_N\", \"Natufian\", \"SHG\", \"Steppe_EMBA\", \"Steppe_Eneolithic\", \"Steppe_IA\", \"Steppe_MLBA\", \"Switzerland_HG\", \"WHG\"]\n",
    "\n",
    "ind_file = pathlib.Path(f\"{merged_prefix}.ind\")\n",
    "ind_df = indfile_to_dataframe(ind_file)\n",
    "\n",
    "modern = [p for p in ind_df.population.unique() if p not in ancient_populations]\n",
    "modern_populations = base_dir / \"westEurasia_ancient\" / \"modern.poplist.txt\"\n",
    "modern_populations.open(\"w\").write(\"\\n\".join(modern))\n",
    "\n",
    "# save a config file used for the Pandora analysis\n",
    "configfile = base_dir / \"westEurasia_ancient\" / \"westEurasia_ancient.pandora.yaml\"\n",
    "save_pandora_config(\n",
    "    westeurasian_prefix,\n",
    "    base_dir / \"westEurasia_ancient\" / \"results\",\n",
    "    smartpca_settings,\n",
    "    configfile,\n",
    "    pca_populations=str(modern_populations)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result analysis\n",
    "## West-eurasian set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pandora.pca import *\n",
    "from pandora.pca_comparison import PCAComparison\n",
    "\n",
    "result_dir = pathlib.Path(\"NearEastPublic\") / \"westEurasia\" / \"results\"\n",
    "\n",
    "support_values = pd.read_table(result_dir / \"pandora.supportValues.txt\", names=[\"sample_id\", \"support\"])\n",
    "# support_values.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        sample_id   support\n467      Jordan62  0.954939\n282     HGDP00629  0.956931\n319     HGDP00680  0.973205\n747      syria520  0.978621\n749        syria7  0.980232\n..            ...       ...\n507   Mordovians4  0.998752\n44    BulgarianD6  0.998786\n487  LithuanianA1  0.998799\n577         PV017  0.998836\n676        bel43s  0.998841\n\n[750 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>467</th>\n      <td>Jordan62</td>\n      <td>0.954939</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>HGDP00629</td>\n      <td>0.956931</td>\n    </tr>\n    <tr>\n      <th>319</th>\n      <td>HGDP00680</td>\n      <td>0.973205</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>syria520</td>\n      <td>0.978621</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>syria7</td>\n      <td>0.980232</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>Mordovians4</td>\n      <td>0.998752</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>BulgarianD6</td>\n      <td>0.998786</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>LithuanianA1</td>\n      <td>0.998799</td>\n    </tr>\n    <tr>\n      <th>577</th>\n      <td>PV017</td>\n      <td>0.998836</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>bel43s</td>\n      <td>0.998841</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_pca = from_smartpca(\n",
    "    result_dir / \"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
